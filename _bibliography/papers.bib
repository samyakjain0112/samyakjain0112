@article{jain2023mechanistically,
  title={Mechanistically analyzing the effects of fine-tuning on procedurally defined tasks},
  author={Jain, Samyak and Kirk, Robert and Lubana, Ekdeep Singh and Dick, Robert P and Tanaka, Hidenori and Grefenstette, Edward and Rockt{\"a}schel, Tim and Krueger, David Scott},
  journal={arXiv preprint arXiv:2311.12786},
  year={2023}
}


@InProceedings{addepalli2022oaat,
    abbr={ECCV},
    author={Sravanti Addepalli* and Samyak Jain* and Gaurang Sriramanan and Venkatesh Babu Radhakrishnan},
    title={Scaling Adversarial Training to Large Perturbation Bounds},
    year={2022},
    url={https://openreview.net/forum?id=SHB_znlW5G7}
}

@InProceedings{Addepalli_2021_CVPR,
    abbr={CVPR Workshops},
    author    = {Sravanti Addepalli* and Samyak Jain* and Gaurang Sriramanan* and R. Venkatesh Babu},
    title     = {Boosting Adversarial Robustness Using Feature Level Stochastic Smoothing},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
    month     = {June},
    year      = {2021},
    pages     = {93-102}
}

@InProceedings{addepalli2022dajat,
    abbr={NeurIPS},
    author={Sravanti Addepalli* and Samyak Jain* and Venkatesh Babu Radhakrishnan},
    title={Efficient and Effective Augmentation Strategy for Adversarial Training},
    year={2022}
}

@InProceedings{JAINDART,
    abbr={CVPR},
    author={Samyak Jain* and Sravanti Addepalli* and Pawan Sahu and Priyam Dey and Venkatesh Babu Radhakrishnan},
    title={DART: Diversify-Aggregate-Repeat Training Improves Generalization of Neural Networks},
    year={2023},
    url={https://arxiv.org/abs/2302.14685}
}
